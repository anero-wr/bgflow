{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b56535a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c7fa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/home/ninarell/OneDrive/WF_GAN_FOR_GLASSES/B_GEN/bgflow\")\n",
    "import bgflow\n",
    "sys.path.insert(0, \"/home/ninarell/OneDrive/WF_GAN_FOR_GLASSES/B_GEN/anode\")\n",
    "import anode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de8d8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from bgflow.utils import (assert_numpy, length_ppp, \n",
    "                          remove_mean, IndexBatchIterator, LossReporter, as_numpy, compute_distances, distance_vectors, distances_from_vectors, length_ppp\n",
    ")\n",
    "from bgflow import (GaussianMCMCSampler, DiffEqFlow, BoltzmannGenerator, Energy, Sampler, \n",
    "                    MultiDoubleWellPotential, MeanFreeNormalDistribution, KernelDynamics)\n",
    "\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf53d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fnames = glob('/home/ninarell/OneDrive/WF_GAN_FOR_GLASSES/LJ_CRYSTAL/T_0.700_box/dumplin/dump.npt_nose_T1.0_P0.*.lammpstrj')\n",
    "#fnames = fnames + glob('/home/ninarell/OneDrive/WF_GAN_FOR_GLASSES/LJ_CRYSTAL/T_0.700_box/dumplin/dump.npt_nose_T0.700_P0.0000020000.lammpstrj')\n",
    "#fnames = glob('/home/ninarell/OneDrive/WF_GAN_FOR_GLASSES/LJ_CRYSTAL/T_0.700_box/dumplin/dump.npt_nose_T1.0_P0.0000000000.lammpstrj')\n",
    "#arrays = [np.loadtxt(f, skiprows=9)[:,2:5] for f in fnames]\n",
    "#coordinates = np.array(arrays)\n",
    "temperature = float(1.00)\n",
    "side= 4 #3.66\n",
    "n_particles = 4 #len(coordinates[0])\n",
    "spacial_dim = 2\n",
    "dim_ics = n_particles * spacial_dim\n",
    "#coordinates=coordinates.reshape(len(arrays), dim_ics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362dd4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  bgflow.distribution.energy import LennardJonesPotentialPPP\n",
    "from  bgflow.distribution.energy import LennardJonesPotential\n",
    "rm = 2**(1./6.)\n",
    "target = LennardJonesPotentialPPP(dim = dim_ics, n_particles = n_particles, side = side, oscillator = False, rm=rm, two_event_dims=False)\n",
    "#target = LennardJonesPotential(dim = dim_ics, n_particles = n_particles,oscillator = False,  two_event_dims=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018e46b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_energy(coordinates, target):\n",
    "    xs = torch.Tensor(coordinates)\n",
    "    #xs = xs.view(-1,10,3)\n",
    "    energy = target.energy(xs).detach().numpy()\n",
    "    x=np.arange(1,len(energy)+1)\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, energy)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    counts, bins = np.histogram(energy, density=True)\n",
    "    plt.yscale(\"log\")\n",
    "    plt.stairs(counts, bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbf6124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_energy(coordinates, target):\n",
    "    xs = torch.Tensor(coordinates)\n",
    "    #xs = xs.view(-1,10,3)\n",
    "    energy = target.energy(xs).detach().numpy()\n",
    "    x=np.arange(1,len(energy)+1)\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, energy)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    counts, bins = np.histogram(energy, density=True)\n",
    "    plt.yscale(\"log\")\n",
    "    plt.stairs(counts, bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec144999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Box constraint\n",
    "def constraint(x):\n",
    "    return length_ppp(x, side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727946ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def generate_random_points(num_points, x_range, y_range):\n",
    "    points = np.empty((num_points, 2))\n",
    "    for i in range(num_points):\n",
    "        x = random.uniform(x_range[0], x_range[1])\n",
    "        y = random.uniform(y_range[0], y_range[1])\n",
    "        points[i] = [x, y]\n",
    "    return points\n",
    "\n",
    "# Parameters\n",
    "num_points = n_particles  # Number of points to generate\n",
    "x_range = (-side, side)  # Range for x coordinates\n",
    "y_range = (-side, side)  # Range for y coordinates\n",
    "\n",
    "# Generate points\n",
    "random_points = generate_random_points(num_points, x_range, y_range)\n",
    "\n",
    "# Print the generated points\n",
    "random_points=random_points.reshape(dim_ics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f12cff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a MCMC sampler to sample from the target energy\n",
    "\n",
    "init_state = torch.Tensor(random_points) #zeros(10,3)\n",
    "\n",
    "mcsampler = GaussianMCMCSampler(target, init_state=init_state, temperature=temperature, box_constraint=constraint, noise_std=0.15)\n",
    "#mcsampler = GaussianMCMCSampler(target, init_state=init_state, temperature=temperature, noise_std=0.15)\n",
    "mcsampler.sample(1000)\n",
    "data = mcsampler.sample(4096)\n",
    "#data = remove_mean(data, n_particles, spacial_dim)\n",
    "while torch.any(abs(data) > side):\n",
    "    data = length_ppp(data, side)\n",
    "    data = remove_mean(data, n_particles, spacial_dim)\n",
    "data = data.view(-1,dim_ics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9e7998",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_energy(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de2c4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now set up a prior\n",
    "\n",
    "from bgflow import NormalDistribution, TruncatedNormalDistribution, MeanFreeNormalDistribution, CircularNormalDistribution\n",
    "\n",
    "#mean = torch.Tensor(data[10]).view(dim_ics)\n",
    "#mean = torch.ones(dim_ics)*0\n",
    "\n",
    "#cov = torch.zeros(dim_ics, dim_ics)\n",
    "#cov = cov.fill_diagonal_(0.004)\n",
    "\n",
    "#prior = NormalDistribution(dim_ics, mean=mean, cov=cov, side=side)\n",
    "prior =  MeanFreeNormalDistribution(dim_ics, n_particles, 0.005, two_event_dims=False, side=side)\n",
    "\n",
    "#mean=torch.ones(dim_ics)*0.01\n",
    "#sigma=torch.ones(dim_ics)*0.2\n",
    "#prior = CircularNormalDistribution(mu=mean, sigma=sigma)\n",
    "\n",
    "# upper_bound=torch.ones(dim_ics)*side\n",
    "# lower_bound=-upper_bound\n",
    "# sigma=torch.ones(dim_ics)*0.02\n",
    "# prior = TruncatedNormalDistribution(mu=mean, sigma=sigma, lower_bound=lower_bound, upper_bound=upper_bound,  sampling_method = \"rejection\" )\n",
    "#prior = TruncatedNormalDistribution(mu=mean, sigma=sigma, lower_bound=lower_bound, upper_bound=upper_bound,  is_learnable=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6704b80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_prior = prior._sample_with_temperature(10000, temperature=temperature)\n",
    "data_prior = prior.sample(1000)\n",
    "#data_prior = data_prior.view(-1, 10, 3)\n",
    "plot_energy(data_prior, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeee7a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlim(-side*2,side*2)\n",
    "plt.ylim(-side*2,side*2)\n",
    "plt.scatter(data_prior[:,0], data_prior[:,1])\n",
    "plt.scatter(data_prior[:,2], data_prior[:,3])\n",
    "plt.scatter(data_prior[:,4], data_prior[:,5])\n",
    "plt.scatter(data_prior[:,6], data_prior[:,7])\n",
    "plt.plot([-side,-side], [-side,side], linestyle=\"--\", color='black')\n",
    "plt.plot([side,side], [-side,side], linestyle=\"--\", color='black')\n",
    "plt.plot([-side,side], [-side,-side], linestyle=\"--\", color='black')\n",
    "plt.plot([-side,side], [side,side], linestyle=\"--\", color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdb09ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set of the equivariant kernel dynamics\n",
    "\n",
    "n_dimensions = spacial_dim\n",
    "d_max = 8\n",
    "mus = torch.linspace(0, d_max, 50) #.cuda()\n",
    "\n",
    "mus.sort()\n",
    "gammas = 0.3 * torch.ones(len(mus)) #.cuda()\n",
    "\n",
    "mus_time = torch.linspace(0, 1, 10) #.cuda()\n",
    "gammas_time = 0.3 * torch.ones(len(mus_time)) #.cuda()\n",
    "\n",
    "\n",
    "kdyn = KernelDynamics(n_particles, n_dimensions, mus, gammas, optimize_d_gammas=True, optimize_t_gammas=True,\n",
    "                      mus_time=mus_time, gammas_time=gammas_time, periodic = True, side = side) #.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d999dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = DiffEqFlow(dynamics = kdyn, side=side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e47d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# having a flow and a prior, we can now define a Boltzmann Generator\n",
    "\n",
    "bg = BoltzmannGenerator(prior, flow, target) #.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e820cbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use DTO in the training process\n",
    "flow._use_checkpoints = True\n",
    "\n",
    "# Anode options\n",
    "options={\n",
    "    \"Nt\": 3,\n",
    "    \"method\": \"RK4\"\n",
    "}\n",
    "flow._kwargs = options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e21871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial training with likelihood maximization on data set\n",
    "\n",
    "n_kl_samples = 64\n",
    "n_batch = 64\n",
    "batch_iter = IndexBatchIterator(len(data), n_batch)\n",
    "\n",
    "optim = torch.optim.Adam(bg.parameters(), lr=1e-4)\n",
    "\n",
    "n_epochs = 10\n",
    "n_report_steps = 4\n",
    "\n",
    "# mixing parameter\n",
    "lambdas = torch.linspace(1., 0.1, n_epochs) #.cuda()\n",
    "\n",
    "reporter = LossReporter(\"NLL\", \"KLL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e5a5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch, lamb in enumerate(lambdas):\n",
    "    for it, idxs in enumerate(batch_iter):\n",
    "        batch = data[idxs] #.cuda()\n",
    "        \n",
    "        optim.zero_grad()\n",
    "\n",
    "        # negative log-likelihood of the batch is equal to the energy of the BG\n",
    "        nll = bg.energy(batch).mean()\n",
    "        # aggregate weighted gradient\n",
    "        (lamb * nll).backward()\n",
    "        \n",
    "        # kl divergence to the target\n",
    "        kll = bg.kldiv(n_kl_samples).mean()\n",
    "\n",
    "        # aggregate weighted gradient\n",
    "        ((1. - lamb) * kll).backward()\n",
    "        \n",
    "        reporter.report(nll, kll)\n",
    "        \n",
    "        optim.step()\n",
    "        \n",
    "        \n",
    "        if it % n_report_steps == 0:\n",
    "            print(\"\\repoch: {0}, iter: {1}/{2}, lambda: {3}, NLL: {4:.4}, KLL: {5:.4}\".format(\n",
    "                    epoch,\n",
    "                    it,\n",
    "                    len(batch_iter),\n",
    "                    lamb,\n",
    "                    *reporter.recent(1).ravel()\n",
    "                ), end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3d89ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "reporter.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9553f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 2000\n",
    "samples, latent, dlogp = bg.sample(n_samples, with_latent=True, with_dlogp=True)\n",
    "log_w = as_numpy(bg.log_weights_given_latent(samples, latent, dlogp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d012365a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_energy(samples, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d4971a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#samples = remove_mean(samples, n_particles, spacial_dim)\n",
    "r = distance_vectors(samples.view(-1, n_particles, spacial_dim))\n",
    "distances_x = as_numpy(distances_from_vectors(length_ppp(r, side)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811563b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(log_w.shape)\n",
    "print(dlogp.shape)\n",
    "print(latent.shape)\n",
    "print(samples.shape)\n",
    "print(distances_x.reshape(-1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d41f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "#plt.plot(d, e, label=\"Groundtruth\", linewidth=4, alpha = 0.5)\n",
    "#data = remove_mean(data, n_particles, spacial_dim)\n",
    "r = distance_vectors(data.view(-1, n_particles, spacial_dim))\n",
    "dists_data = as_numpy(distances_from_vectors(length_ppp(r,  side)))\n",
    "#data_prior = remove_mean(data_prior, n_particles, spacial_dim)\n",
    "r = distance_vectors(data_prior.view(-1, n_particles, spacial_dim))\n",
    "dists_data_prior = as_numpy(distances_from_vectors(length_ppp(r,  side)))\n",
    "\n",
    "\n",
    "plt.hist(dists_data.reshape(-1), bins=50, label=\"training samples\", alpha=0.5, density=True, histtype='step', linewidth=4);\n",
    "plt.hist(dists_data_prior.reshape(-1), bins=50, label=\"prior samples\", alpha=0.5, density=True, histtype='step', linewidth=4);\n",
    "plt.hist(distances_x.reshape(-1), bins=50, label=\"bg samples\", alpha=0.7, density=True, histtype='step', linewidth=4);\n",
    "#plt.hist(distances_x.reshape(-1), bins=50, label=\"reweighted bg samples\", alpha=0.7, density=True, histtype='step', linewidth=4, weights=np.exp(log_w));\n",
    "plt.xlim(0,np.sqrt(spacial_dim*side*side)+2)\n",
    "plt.legend(fontsize=35)\n",
    "plt.xlabel(\"u(x)\", fontsize=45)  \n",
    "plt.xticks(fontsize=45) \n",
    "plt.yticks(fontsize=45);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b794228",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(np.any(distances_x> np.sqrt(side*side*2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96015411",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlim(-side*3,side*3)\n",
    "plt.ylim(-side*3,side*3)\n",
    "samplesnp = samples.detach().cpu().numpy()\n",
    "plt.scatter(samplesnp[:,0], samplesnp[:,1])\n",
    "plt.scatter(samplesnp[:,2], samplesnp[:,3])\n",
    "plt.scatter(samplesnp[:,4], samplesnp[:,5])\n",
    "plt.scatter(samplesnp[:,6], samplesnp[:,7])\n",
    "plt.plot([-side,-side], [-side,side], linestyle=\"--\", color='black')\n",
    "plt.plot([side,side], [-side,side], linestyle=\"--\", color='black')\n",
    "plt.plot([-side,side], [-side,-side], linestyle=\"--\", color='black')\n",
    "plt.plot([-side,side], [side,side], linestyle=\"--\", color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aba054",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlim(-side*2,side*2)\n",
    "plt.ylim(-side*2,side*2)\n",
    "datanp = data.detach().cpu().numpy()\n",
    "plt.scatter(datanp[:,0], datanp[:,1])\n",
    "plt.scatter(datanp[:,2], datanp[:,3])\n",
    "plt.scatter(datanp[:,4], datanp[:,5])\n",
    "plt.scatter(datanp[:,6], datanp[:,7])\n",
    "plt.plot([-side,-side], [-side,side], linestyle=\"--\", color='black')\n",
    "plt.plot([side,side], [-side,side], linestyle=\"--\", color='black')\n",
    "plt.plot([-side,side], [-side,-side], linestyle=\"--\", color='black')\n",
    "plt.plot([-side,side], [side,side], linestyle=\"--\", color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baee1e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "r= torch.linspace(0.5, 5, 100)\n",
    "def lennard_jones_energy_torch(r, eps=1.0, rm=1.0, rct=2.5):\n",
    "\n",
    "    r = torch.where((r < rct).clone().detach(), r, torch.tensor(1000000.))\n",
    "    r_int=0.8\n",
    "    b= 0.02\n",
    "    r = torch.where((r < r_int).clone().detach(), b * r / r_int + r_int - b  , r)\n",
    "    return eps * ((rm / r) ** 12 - 2 * (rm / r) ** 6) / 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0d1b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "lj = lennard_jones_energy_torch(r)\n",
    "plt.plot(r, lennard_jones_energy_torch(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bddea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "\n",
    "distances_x = as_numpy(compute_distances(samples,  n_particles, n_dimensions))\n",
    "dist_data = as_numpy(compute_distances(data,  n_particles, n_dimensions))\n",
    "dist_data_prior = as_numpy(compute_distances(data_prior,  n_particles, n_dimensions))\n",
    "\n",
    "plt.hist(dists_data.reshape(-1), bins=50, label=\"training samples\", alpha=0.5, density=True, histtype='step', linewidth=4);\n",
    "plt.hist(dists_data_prior.reshape(-1), bins=50, label=\"prior samples\", alpha=0.5, density=True, histtype='step', linewidth=4);\n",
    "plt.hist(distances_x.reshape(-1), bins=50, label=\"bg samples\", alpha=0.7, density=True, histtype='step', linewidth=4);\n",
    "#plt.hist(distances_x.reshape(-1), bins=50, label=\"reweighted bg samples\", alpha=0.7, density=True, histtype='step', linewidth=4, weights=np.exp(log_w));\n",
    "plt.xlim(0,np.sqrt(spacial_dim*side*side)+5)\n",
    "plt.legend(fontsize=35)\n",
    "plt.xlabel(\"u(x)\", fontsize=45)  \n",
    "plt.xticks(fontsize=45) \n",
    "plt.yticks(fontsize=45);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6990fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(log_w.shape)\n",
    "print(dlogp.shape)\n",
    "print(latent.shape)\n",
    "print(samples.shape)\n",
    "print(distances_x.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bg",
   "language": "python",
   "name": "bg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
