{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b56535a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c7fa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/home/ninarell/OneDrive/WF_GAN_FOR_GLASSES/B_GEN/bgflow\")\n",
    "import bgflow\n",
    "sys.path.insert(0, \"/home/ninarell/OneDrive/WF_GAN_FOR_GLASSES/B_GEN/anode\")\n",
    "import anode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de8d8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from bgflow.utils import (assert_numpy, length_ppp, \n",
    "                          remove_mean, IndexBatchIterator, LossReporter, as_numpy, compute_distances, distance_vectors, distances_from_vectors, length_ppp\n",
    ")\n",
    "from bgflow import (GaussianMCMCSampler, DiffEqFlow, BoltzmannGenerator, Energy, Sampler, \n",
    "                    MultiDoubleWellPotential, MeanFreeNormalDistribution, KernelDynamics)\n",
    "\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf53d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fnames = glob('/home/ninarell/OneDrive/WF_GAN_FOR_GLASSES/LJ_CRYSTAL/T_0.700_box/dumplin/dump.npt_nose_T1.0_P0.*.lammpstrj')\n",
    "#coordinates = np.([np.loadtxt(f, skiprows=9)[:,2:5] for f in fnames])\n",
    "temperature = float(1.)\n",
    "side =5.63 #3.98 #2.52 #2.18 # 1.78\n",
    "n_particles = 10 #len(coordinates[0])\n",
    "spacial_dim = 2\n",
    "dim_ics = n_particles * spacial_dim\n",
    "#coordinates=coordinates.reshape(len(arrays), dim_ics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362dd4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  bgflow.distribution.energy import LennardJonesPotentialPPP\n",
    "from  bgflow.distribution.energy import LennardJonesPotential\n",
    "rm = 2**(1./6.)\n",
    "target = LennardJonesPotentialPPP(dim = dim_ics, n_particles = n_particles, side = side, oscillator = False, rm=rm, two_event_dims=False)\n",
    "#target = LennardJonesPotential(dim = dim_ics, n_particles = n_particles,oscillator = False, rm=rm, two_event_dims=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018e46b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def plot_energy(coordinates, target):\n",
    "#    xs = torch.Tensor(coordinates)\n",
    "#    #xs = xs.view(-1,10,3)\n",
    "#    energy = target.energy(xs).detach().numpy()\n",
    "#    x=np.arange(1,len(energy)+1)\n",
    "\n",
    "#    fig = plt.figure(figsize=(12, 4))\n",
    "#    plt.subplot(1, 2, 1)\n",
    "#    plt.plot(x, energy)\n",
    "\n",
    "#    plt.subplot(1, 2, 2)\n",
    "#    counts, bins = np.histogram(energy, density=True)\n",
    "#    plt.yscale(\"log\")\n",
    "#    plt.stairs(counts, bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbf6124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_energy(coordinates, target):\n",
    "    fig = plt.figure(figsize=(9, 9))\n",
    "\n",
    "    energies=[]\n",
    "    xx=[]\n",
    "    for coord in coordinates:\n",
    "        xs = torch.Tensor(coord)\n",
    "        #xs = xs.view(-1,10,3)\n",
    "        energy = target.energy(xs).detach().numpy()\n",
    "        x=np.arange(1,len(energy)+1)\n",
    "        xx.append(x)\n",
    "        energies.append(energy)\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for energy,x in zip(energies,xx):\n",
    "        plt.plot(x, energy)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.yscale(\"log\")\n",
    "    for energy in energies:\n",
    "        counts, bins = np.histogram(energy, density=True)\n",
    "        plt.stairs(counts, bins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9426443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distance_histograms(samples, data, data_prior, n_particles, n_dimensions, d, e, side, log_w):\n",
    "    fig = plt.figure(figsize=(16, 9))\n",
    "\n",
    "    distances_x = as_numpy(compute_distances(samples, n_particles, n_dimensions))\n",
    "    dists_data = as_numpy(compute_distances(data, n_particles, n_dimensions))\n",
    "    dists_data_prior = as_numpy(compute_distances(data_prior, n_particles, n_dimensions))\n",
    "\n",
    "    #plt.plot(d, e, label=\"Groundtruth\", linewidth=4, alpha=0.9)\n",
    "    plt.hist(dists_data.reshape(-1), bins=50, label=\"training samples\", alpha=0.5, density=True, histtype='step', linewidth=4)\n",
    "    plt.hist(dists_data_prior.reshape(-1), bins=50, label=\"prior samples\", alpha=0.5, density=True, histtype='step', linewidth=4)\n",
    "    plt.hist(distances_x.reshape(-1), bins=50, label=\"bg samples\", alpha=0.7, density=True, histtype='step', linewidth=4)\n",
    "\n",
    "    repeat_counts = (len(distances_x) * np.exp(log_w) / np.sum(np.exp(log_w))).astype(int)\n",
    "    distances_x = np.repeat(distances_x, repeat_counts, axis=0)\n",
    "    log_w_weighted = np.repeat(log_w, repeat_counts)\n",
    "    log_w_weighted = np.repeat(log_w_weighted, distances_x.shape[1])\n",
    "    #plt.hist(distances_x.reshape(-1), bins=50, label=\"reweighted bg samples\", alpha=0.7, density=True, histtype='step', linewidth=4, weights=np.exp(log_w_weighted))\n",
    "\n",
    "    plt.xlim(0, side*side)\n",
    "    plt.legend(fontsize=35)\n",
    "    plt.xlabel(\"u(x)\", fontsize=45)\n",
    "    plt.xticks(fontsize=45)\n",
    "    plt.yticks(fontsize=45)\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98cb138",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter_with_limits_and_lines(data, side, limit_factor):\n",
    "    plt.xlim(-side*limit_factor, side*limit_factor)\n",
    "    plt.ylim(-side*limit_factor, side*limit_factor)\n",
    "    plt.scatter(data[:,0], data[:,1])\n",
    "    plt.scatter(data[:,2], data[:,3])\n",
    "    plt.scatter(data[:,4], data[:,5])\n",
    "    #plt.scatter(data[:,6], data[:,7])\n",
    "    plt.plot([-side, -side], [-side, side], linestyle=\"--\", color='black')\n",
    "    plt.plot([side, side], [-side, side], linestyle=\"--\", color='black')\n",
    "    plt.plot([-side, side], [-side, -side], linestyle=\"--\", color='black')\n",
    "    plt.plot([-side, side], [side, side], linestyle=\"--\", color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde1ec23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter_with_limits_and_lines_ppp(data, side, limit_factor):\n",
    "\n",
    "    plot_scatter_with_limits_and_lines(data, side, limit_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458e4cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_ppp(data):\n",
    "    data = remove_mean(data, n_particles, spacial_dim)\n",
    "    while torch.any(abs(data) > side):\n",
    "        data = length_ppp(data, side)\n",
    "        data = remove_mean(data, n_particles, spacial_dim)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451566d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate(lr,epoch,it,tau):\n",
    "    xi_0=0.9\n",
    "    xi_f=0.1\n",
    "    A_l = lr*np.power(xi_0,epoch)\n",
    "    dumping = 1+np.cos(np.pi*it/tau)\n",
    "    return A_l * ((1-xi_f)*dumping/2 + xi_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f12cff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a MCMC sampler to sample from the target energy\n",
    "#Box constraint\n",
    "def constraint(x):\n",
    "    return length_ppp(x, side)\n",
    "\n",
    "#init_state = torch.Tensor([-0.5,-0.5,-0.5,0.5,0.5,-0.5,0.5,0.5])\n",
    "#init_state = torch.Tensor([-0.5,0, 0.5,0, 0, 0.5, 0, -0.5])\n",
    "#init_state = torch.Tensor([-0.5,0,  0.5,0, 0,0.866, 0,-0.866]) #, 0, 0.5, 0, -0.5])\n",
    "init_state = torch.Tensor([-0.5,0, 0.5,0, 0,0.866, 0,-0.866, -1.5,0, 1.5,0, 0,1.866, 0,-1.866, 1.866,1.866, -1.866,-1.866])\n",
    "mc_step = 0.2\n",
    "mcsampler = GaussianMCMCSampler(target, init_state=init_state, temperature=temperature, box_constraint=constraint, noise_std=mc_step)\n",
    "void = mcsampler.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d58763",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data=4096 #512 #8192 #16384 2048\n",
    "data = mcsampler.sample(n_data)\n",
    "apply_ppp(data)\n",
    "data = data.view(-1,dim_ics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9e7998",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_energy([data], target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6c2742",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_scatter_with_limits_and_lines(data, side, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5675e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### now set up a prior\n",
    "\n",
    "from bgflow import NormalDistribution, TruncatedNormalDistribution, MeanFreeNormalDistribution, CircularNormalDistribution\n",
    "\n",
    "prior =  MeanFreeNormalDistribution(dim_ics, n_particles, std=1.,two_event_dims=False) #.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6704b80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prior = prior.sample(1000, temperature=temperature)\n",
    "#data_prior = prior.sample(1000)\n",
    "#data_prior = data_prior.view(-1, 10, 3)\n",
    "plot_energy([data_prior,data], target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5d5b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4624d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter_with_limits_and_lines(data_prior, side, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdb09ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set of the equivariant kernel dynamics\n",
    "\n",
    "n_dimensions = spacial_dim\n",
    "d_max = 8\n",
    "mus = torch.linspace(0, d_max, 50) #.cuda()\n",
    "\n",
    "mus.sort()\n",
    "gammas = 0.3 * torch.ones(len(mus)) #.cuda()\n",
    "\n",
    "mus_time = torch.linspace(0, 1, 10) #.cuda()\n",
    "gammas_time = 0.3 * torch.ones(len(mus_time)) #.cuda()\n",
    "\n",
    "\n",
    "kdyn = KernelDynamics(n_particles, n_dimensions, mus, gammas, optimize_d_gammas=True, optimize_t_gammas=True,\n",
    "                      mus_time=mus_time, gammas_time=gammas_time, periodic = True, side = side) #.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d999dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = DiffEqFlow(dynamics = kdyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e47d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# having a flow and a prior, we can now define a Boltzmann Generator\n",
    "\n",
    "bg = BoltzmannGenerator(prior, flow, target) #.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e53dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 2000\n",
    "samples, latent, dlogp = bg.sample(n_samples, with_latent=True, with_dlogp=True, temperature=temperature)\n",
    "log_w = as_numpy(bg.log_weights_given_latent(samples, latent, dlogp, temperature=temperature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dc9009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lennard_jones_energy_torch(r, eps=1.0, rm=rm):\n",
    "    lj = eps * ((rm / r) ** 12 - 2 * (rm / r) ** 6)\n",
    "    return lj\n",
    "d = torch.linspace(0, 5, 1000).view(-1, 1) + 1e-6 \n",
    "u = torch.exp(-(lennard_jones_energy_torch(d).view(-1, 1))/(temperature*1)).sum(dim=-1, keepdim=True)  * d.abs() **(dim_ics // n_particles - 1)\n",
    "Z = (u * 1 / (len(d) / (d.max() - d.min()))).sum()\n",
    "e = u / Z \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bb2b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig = plot_distance_histograms(apply_ppp(samples), data, data_prior, n_particles, n_dimensions, d, e, side, log_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e820cbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use DTO in the training process\n",
    "flow._use_checkpoints = True\n",
    "\n",
    "# Anode options\n",
    "options={\n",
    "    \"Nt\": 3,\n",
    "    \"method\": \"RK4\"\n",
    "}\n",
    "flow._kwargs = options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e21871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial training with likelihood maximization on data set\n",
    "\n",
    "n_kl_samples = 64\n",
    "n_batch = 64\n",
    "batch_iter = IndexBatchIterator(len(data), n_batch)\n",
    "\n",
    "lr=8e-3\n",
    "tau= n_data/n_batch\n",
    "optim = torch.optim.Adam(bg.parameters(), lr=lr, weight_decay=lr/50)\n",
    "\n",
    "n_epochs = 2\n",
    "n_report_steps = 4\n",
    "\n",
    "# mixing parameter\n",
    "lambdas = torch.linspace(1., 0.1, n_epochs) #.cuda()\n",
    "\n",
    "reporter = LossReporter(\"NLL\", \"KLL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e5a5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch, lamb in enumerate(lambdas):\n",
    "    #(1 - np.power(-float(epoch)/float(n_epochs+1), 4))  \n",
    "            \n",
    "    for it, idxs in enumerate(batch_iter):   \n",
    "        batch = data[idxs] #.cuda()\n",
    "        \n",
    "        for g in optim.param_groups:\n",
    "            g['lr'] = learning_rate(lr,epoch,it,tau)                 #lr * np.exp(-10*float(epoch)/float(n_epochs)) \n",
    "            g['weight_decay'] = learning_rate(lr,epoch,it,tau)/50\n",
    "            \n",
    "        optim.zero_grad()\n",
    "\n",
    "        # negative log-likelihood of the batch is equal to the energy of the BG\n",
    "        nll = bg.energy(batch, temperature=temperature).mean()\n",
    "        # aggregate weighted gradient\n",
    "        (lamb * nll).backward()\n",
    "        \n",
    "        # kl divergence to the target\n",
    "        kll = bg.kldiv(n_kl_samples, temperature=temperature).mean()\n",
    "\n",
    "        # aggregate weighted gradient\n",
    "        ((1. - lamb) * kll).backward()\n",
    "        \n",
    "        reporter.report(nll, kll)\n",
    "        \n",
    "        optim.step()\n",
    "        \n",
    "        \n",
    "        if it % n_report_steps == 0:\n",
    "            print(\"\\repoch: {0}, iter: {1}/{2}, lambda: {3}, NLL: {4:.4}, KLL: {5:.4}\".format(\n",
    "                    epoch,\n",
    "                    it,\n",
    "                    len(batch_iter),\n",
    "                    lamb,\n",
    "                    *reporter.recent(1).ravel()\n",
    "                ), end=\"\")\n",
    "            \n",
    "        #n_samples = 2000\n",
    "        #samples, latent, dlogp = bg.sample(n_samples, with_latent=True, with_dlogp=True, temperature=temperature)\n",
    "        #log_w = as_numpy(bg.log_weights_given_latent(samples, latent, dlogp))\n",
    "        #repeat_counts = (len(samples)* np.exp(log_w)/np.sum(np.exp(log_w))).astype(int)\n",
    "        #samples = samples.view(-1,n_particles, n_dimensions)\n",
    "        #replicated_samples = np.repeat(samples.detach().cpu().numpy(), repeat_counts, axis=0)\n",
    "        #replicated_samples = replicated_samples.reshape((replicated_samples.shape[0], -1))\n",
    "        #fig = plot_energy([replicated_samples,data], target)\n",
    "        #fig = plot_distance_histograms(samples, data, data_prior, n_particles, n_dimensions, d, e, side, log_w)\n",
    "        #filename = '/home/ninarell/Desktop/FIG_ENERGY/fig_'+str(epoch)+\".png\"\n",
    "        #fig.savefig(filename, dpi=fig.dpi, format='png')\n",
    "        # plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bf7938",
   "metadata": {},
   "outputs": [],
   "source": [
    "reporter.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d41f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 20000\n",
    "samples, latent, dlogp = bg.sample(n_samples, with_latent=True, with_dlogp=True, temperature=temperature)\n",
    "log_w = as_numpy(bg.log_weights_given_latent(samples, latent, dlogp, temperature=temperature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f209e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_counts = (len(samples)* np.exp(log_w)/np.sum(np.exp(log_w))).astype(int)\n",
    "samples = samples.view(-1,n_particles, n_dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d7de1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(repeat_counts>0)[0].size/n_samples*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57da24bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(repeat_counts>0)[0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe6c900",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.power(np.exp(log_w),2))/np.power(np.mean(np.exp(log_w)),2)/n_samples*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3b2d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "replicated_samples = np.repeat(samples.detach().cpu().numpy(), repeat_counts, axis=0)\n",
    "replicated_samples = replicated_samples.reshape((replicated_samples.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416d7a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_distance_histograms(apply_ppp(samples), data, data_prior, n_particles, n_dimensions, d, e, side, log_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996b0c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_scatter_with_limits_and_lines_ppp(length_ppp(torch.Tensor(replicated_samples),side), side, 2)\n",
    "#plot_scatter_with_limits_and_lines_ppp(apply_ppp(torch.Tensor(replicated_samples)), side, 2)\n",
    "plot_scatter_with_limits_and_lines_ppp(apply_ppp(torch.Tensor(samples.view(-1, dim_ics).detach().numpy())), side, 2)\n",
    "#plot_scatter_with_limits_and_lines_ppp(torch.Tensor(replicated_samples), side, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fb03db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter_with_limits_and_lines_ppp(apply_ppp(torch.Tensor(replicated_samples)), side, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375752ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_energy([samples.view(-1, dim_ics),data], target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731630ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_energy([replicated_samples,data], target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bg",
   "language": "python",
   "name": "bg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
